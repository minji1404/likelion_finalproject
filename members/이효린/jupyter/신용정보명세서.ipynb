{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10471e72-5693-492e-b152-badbb7616950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“„ ìœ„ì¹˜: C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201807_201807.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ”¹ 1. ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/train/2.ì‹ ìš©ì •ë³´/201807_train_ì‹ ìš©ì •ë³´.parquet\",\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/test/2.ì‹ ìš©ì •ë³´/201807_test_ì‹ ìš©ì •ë³´.parquet\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 2. ë³‘í•©ìš© ë¦¬ìŠ¤íŠ¸\n",
    "df_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_parquet(path)\n",
    "    ê¸°ì¤€ë…„ì›” = os.path.basename(path).split('_')[0]\n",
    "    df['ê¸°ì¤€ë…„ì›”'] = ê¸°ì¤€ë…„ì›”\n",
    "    df_list.append(df)\n",
    "\n",
    "# ğŸ”¹ 3. ë³‘í•©\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ğŸ”¹ 4. ëª…ì„¸ì„œ êµ¬ì„±\n",
    "desc_list = []\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col == 'SEGMENT':\n",
    "        continue  # â— ì œì™¸í•  ì»¬ëŸ¼\n",
    "\n",
    "    col_type = str(merged_df[col].dtype)\n",
    "    nulls = merged_df[col].isnull().sum()\n",
    "    nunique = merged_df[col].nunique()\n",
    "    var_type = 'ì—°ì†í˜•' if col_type in ['int64', 'float64'] else 'ë²”ì£¼í˜•'\n",
    "\n",
    "    # ì´ìƒì¹˜ ê³„ì‚° (ì—°ì†í˜•ë§Œ)\n",
    "    if var_type == 'ì—°ì†í˜•':\n",
    "        Q1 = merged_df[col].quantile(0.25)\n",
    "        Q3 = merged_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = merged_df[\n",
    "            (merged_df[col] < Q1 - 1.5 * IQR) | (merged_df[col] > Q3 + 1.5 * IQR)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        outliers = 'N/A'\n",
    "\n",
    "    # ì˜ˆì‹œê°’: ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  ê³ ìœ ê°’ ìƒìœ„ 5ê°œ\n",
    "    example_value = list(merged_df[col].dropna().unique()[:5])\n",
    "\n",
    "    desc_list.append({\n",
    "        'ì»¬ëŸ¼ëª…': col,\n",
    "        'ë°ì´í„° íƒ€ì…': col_type,\n",
    "        'ê²°ì¸¡ì¹˜ ìˆ˜': nulls,\n",
    "        'ê³ ìœ ê°’ ìˆ˜': nunique,\n",
    "        'ì´ìƒì¹˜ ìˆ˜': outliers,\n",
    "        'ë³€ìˆ˜ ìœ í˜•': var_type,\n",
    "        'ì˜ˆì‹œê°’': example_value,\n",
    "        'ì²˜ë¦¬ ê³„íš': ''\n",
    "    })\n",
    "\n",
    "# ğŸ”¹ 5. ëª…ì„¸ì„œ ì €ì¥\n",
    "desc_df = pd.DataFrame(desc_list)\n",
    "save_path = \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201807_201807.xlsx\"\n",
    "desc_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\\nğŸ“„ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62508cc8-d2a0-4367-a4f4-eca6e8ba08c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“„ ìœ„ì¹˜: C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201808_201808.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ”¹ 1. ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/train/2.ì‹ ìš©ì •ë³´/201808_train_ì‹ ìš©ì •ë³´.parquet\",\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/test/2.ì‹ ìš©ì •ë³´/201808_test_ì‹ ìš©ì •ë³´.parquet\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 2. ë³‘í•©ìš© ë¦¬ìŠ¤íŠ¸\n",
    "df_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_parquet(path)\n",
    "    ê¸°ì¤€ë…„ì›” = os.path.basename(path).split('_')[0]\n",
    "    df['ê¸°ì¤€ë…„ì›”'] = ê¸°ì¤€ë…„ì›”\n",
    "    df_list.append(df)\n",
    "\n",
    "# ğŸ”¹ 3. ë³‘í•©\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ğŸ”¹ 4. ëª…ì„¸ì„œ êµ¬ì„±\n",
    "desc_list = []\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col == 'SEGMENT':\n",
    "        continue  # â— ì œì™¸í•  ì»¬ëŸ¼\n",
    "\n",
    "    col_type = str(merged_df[col].dtype)\n",
    "    nulls = merged_df[col].isnull().sum()\n",
    "    nunique = merged_df[col].nunique()\n",
    "    var_type = 'ì—°ì†í˜•' if col_type in ['int64', 'float64'] else 'ë²”ì£¼í˜•'\n",
    "\n",
    "    # ì´ìƒì¹˜ ê³„ì‚° (ì—°ì†í˜•ë§Œ)\n",
    "    if var_type == 'ì—°ì†í˜•':\n",
    "        Q1 = merged_df[col].quantile(0.25)\n",
    "        Q3 = merged_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = merged_df[\n",
    "            (merged_df[col] < Q1 - 1.5 * IQR) | (merged_df[col] > Q3 + 1.5 * IQR)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        outliers = 'N/A'\n",
    "\n",
    "    # ì˜ˆì‹œê°’: ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  ê³ ìœ ê°’ ìƒìœ„ 5ê°œ\n",
    "    example_value = list(merged_df[col].dropna().unique()[:5])\n",
    "\n",
    "    desc_list.append({\n",
    "        'ì»¬ëŸ¼ëª…': col,\n",
    "        'ë°ì´í„° íƒ€ì…': col_type,\n",
    "        'ê²°ì¸¡ì¹˜ ìˆ˜': nulls,\n",
    "        'ê³ ìœ ê°’ ìˆ˜': nunique,\n",
    "        'ì´ìƒì¹˜ ìˆ˜': outliers,\n",
    "        'ë³€ìˆ˜ ìœ í˜•': var_type,\n",
    "        'ì˜ˆì‹œê°’': example_value,\n",
    "        'ì²˜ë¦¬ ê³„íš': ''\n",
    "    })\n",
    "# ğŸ”¹ 5. ëª…ì„¸ì„œ ì €ì¥\n",
    "desc_df = pd.DataFrame(desc_list)\n",
    "save_path = \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201808_201808.xlsx\"\n",
    "desc_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\\nğŸ“„ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f604c4-345c-4fdc-9e2c-3ebb280c40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“„ ìœ„ì¹˜: C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201809_201809.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ”¹ 1. ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/train/2.ì‹ ìš©ì •ë³´/201809_train_ì‹ ìš©ì •ë³´.parquet\",\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/test/2.ì‹ ìš©ì •ë³´/201809_test_ì‹ ìš©ì •ë³´.parquet\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 2. ë³‘í•©ìš© ë¦¬ìŠ¤íŠ¸\n",
    "df_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_parquet(path)\n",
    "    ê¸°ì¤€ë…„ì›” = os.path.basename(path).split('_')[0]\n",
    "    df['ê¸°ì¤€ë…„ì›”'] = ê¸°ì¤€ë…„ì›”\n",
    "    df_list.append(df)\n",
    "\n",
    "# ğŸ”¹ 3. ë³‘í•©\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ğŸ”¹ 4. ëª…ì„¸ì„œ êµ¬ì„±\n",
    "desc_list = []\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col == 'SEGMENT':\n",
    "        continue  # â— ì œì™¸í•  ì»¬ëŸ¼\n",
    "\n",
    "    col_type = str(merged_df[col].dtype)\n",
    "    nulls = merged_df[col].isnull().sum()\n",
    "    nunique = merged_df[col].nunique()\n",
    "    var_type = 'ì—°ì†í˜•' if col_type in ['int64', 'float64'] else 'ë²”ì£¼í˜•'\n",
    "\n",
    "    # ì´ìƒì¹˜ ê³„ì‚° (ì—°ì†í˜•ë§Œ)\n",
    "    if var_type == 'ì—°ì†í˜•':\n",
    "        Q1 = merged_df[col].quantile(0.25)\n",
    "        Q3 = merged_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = merged_df[\n",
    "            (merged_df[col] < Q1 - 1.5 * IQR) | (merged_df[col] > Q3 + 1.5 * IQR)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        outliers = 'N/A'\n",
    "\n",
    "    # ì˜ˆì‹œê°’: ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  ê³ ìœ ê°’ ìƒìœ„ 5ê°œ\n",
    "    example_value = list(merged_df[col].dropna().unique()[:5])\n",
    "\n",
    "    desc_list.append({\n",
    "        'ì»¬ëŸ¼ëª…': col,\n",
    "        'ë°ì´í„° íƒ€ì…': col_type,\n",
    "        'ê²°ì¸¡ì¹˜ ìˆ˜': nulls,\n",
    "        'ê³ ìœ ê°’ ìˆ˜': nunique,\n",
    "        'ì´ìƒì¹˜ ìˆ˜': outliers,\n",
    "        'ë³€ìˆ˜ ìœ í˜•': var_type,\n",
    "        'ì˜ˆì‹œê°’': example_value,\n",
    "        'ì²˜ë¦¬ ê³„íš': ''\n",
    "    })\n",
    "\n",
    "# ğŸ”¹ 5. ëª…ì„¸ì„œ ì €ì¥\n",
    "desc_df = pd.DataFrame(desc_list)\n",
    "save_path = \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201809_201809.xlsx\"\n",
    "desc_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\\nğŸ“„ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6528cb-b830-4eb2-8a66-163a3e39017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“„ ìœ„ì¹˜: C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201810_201810.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ”¹ 1. ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/train/2.ì‹ ìš©ì •ë³´/201810_train_ì‹ ìš©ì •ë³´.parquet\",\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/test/2.ì‹ ìš©ì •ë³´/201810_test_ì‹ ìš©ì •ë³´.parquet\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 2. ë³‘í•©ìš© ë¦¬ìŠ¤íŠ¸\n",
    "df_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_parquet(path)\n",
    "    ê¸°ì¤€ë…„ì›” = os.path.basename(path).split('_')[0]\n",
    "    df['ê¸°ì¤€ë…„ì›”'] = ê¸°ì¤€ë…„ì›”\n",
    "    df_list.append(df)\n",
    "\n",
    "# ğŸ”¹ 3. ë³‘í•©\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ğŸ”¹ 4. ëª…ì„¸ì„œ êµ¬ì„±\n",
    "desc_list = []\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col == 'SEGMENT':\n",
    "        continue  # â— ì œì™¸í•  ì»¬ëŸ¼\n",
    "\n",
    "    col_type = str(merged_df[col].dtype)\n",
    "    nulls = merged_df[col].isnull().sum()\n",
    "    nunique = merged_df[col].nunique()\n",
    "    var_type = 'ì—°ì†í˜•' if col_type in ['int64', 'float64'] else 'ë²”ì£¼í˜•'\n",
    "\n",
    "    # ì´ìƒì¹˜ ê³„ì‚° (ì—°ì†í˜•ë§Œ)\n",
    "    if var_type == 'ì—°ì†í˜•':\n",
    "        Q1 = merged_df[col].quantile(0.25)\n",
    "        Q3 = merged_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = merged_df[\n",
    "            (merged_df[col] < Q1 - 1.5 * IQR) | (merged_df[col] > Q3 + 1.5 * IQR)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        outliers = 'N/A'\n",
    "\n",
    "    # ì˜ˆì‹œê°’: ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  ê³ ìœ ê°’ ìƒìœ„ 5ê°œ\n",
    "    example_value = list(merged_df[col].dropna().unique()[:5])\n",
    "\n",
    "    desc_list.append({\n",
    "        'ì»¬ëŸ¼ëª…': col,\n",
    "        'ë°ì´í„° íƒ€ì…': col_type,\n",
    "        'ê²°ì¸¡ì¹˜ ìˆ˜': nulls,\n",
    "        'ê³ ìœ ê°’ ìˆ˜': nunique,\n",
    "        'ì´ìƒì¹˜ ìˆ˜': outliers,\n",
    "        'ë³€ìˆ˜ ìœ í˜•': var_type,\n",
    "        'ì˜ˆì‹œê°’': example_value,\n",
    "        'ì²˜ë¦¬ ê³„íš': ''\n",
    "    })\n",
    "\n",
    "# ğŸ”¹ 5. ëª…ì„¸ì„œ ì €ì¥\n",
    "desc_df = pd.DataFrame(desc_list)\n",
    "save_path = \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201810_201810.xlsx\"\n",
    "desc_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\\nğŸ“„ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b5f854-12be-4d50-8e9c-5f11d3cb7096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“„ ìœ„ì¹˜: C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201811_201811.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ”¹ 1. ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/train/2.ì‹ ìš©ì •ë³´/201811_train_ì‹ ìš©ì •ë³´.parquet\",\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/test/2.ì‹ ìš©ì •ë³´/201811_test_ì‹ ìš©ì •ë³´.parquet\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 2. ë³‘í•©ìš© ë¦¬ìŠ¤íŠ¸\n",
    "df_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_parquet(path)\n",
    "    ê¸°ì¤€ë…„ì›” = os.path.basename(path).split('_')[0]\n",
    "    df['ê¸°ì¤€ë…„ì›”'] = ê¸°ì¤€ë…„ì›”\n",
    "    df_list.append(df)\n",
    "\n",
    "# ğŸ”¹ 3. ë³‘í•©\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ğŸ”¹ 4. ëª…ì„¸ì„œ êµ¬ì„±\n",
    "desc_list = []\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col == 'SEGMENT':\n",
    "        continue  # â— ì œì™¸í•  ì»¬ëŸ¼\n",
    "\n",
    "    col_type = str(merged_df[col].dtype)\n",
    "    nulls = merged_df[col].isnull().sum()\n",
    "    nunique = merged_df[col].nunique()\n",
    "    var_type = 'ì—°ì†í˜•' if col_type in ['int64', 'float64'] else 'ë²”ì£¼í˜•'\n",
    "\n",
    "    # ì´ìƒì¹˜ ê³„ì‚° (ì—°ì†í˜•ë§Œ)\n",
    "    if var_type == 'ì—°ì†í˜•':\n",
    "        Q1 = merged_df[col].quantile(0.25)\n",
    "        Q3 = merged_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = merged_df[\n",
    "            (merged_df[col] < Q1 - 1.5 * IQR) | (merged_df[col] > Q3 + 1.5 * IQR)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        outliers = 'N/A'\n",
    "\n",
    "    # ì˜ˆì‹œê°’: ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  ê³ ìœ ê°’ ìƒìœ„ 5ê°œ\n",
    "    example_value = list(merged_df[col].dropna().unique()[:5])\n",
    "\n",
    "    desc_list.append({\n",
    "        'ì»¬ëŸ¼ëª…': col,\n",
    "        'ë°ì´í„° íƒ€ì…': col_type,\n",
    "        'ê²°ì¸¡ì¹˜ ìˆ˜': nulls,\n",
    "        'ê³ ìœ ê°’ ìˆ˜': nunique,\n",
    "        'ì´ìƒì¹˜ ìˆ˜': outliers,\n",
    "        'ë³€ìˆ˜ ìœ í˜•': var_type,\n",
    "        'ì˜ˆì‹œê°’': example_value,\n",
    "        'ì²˜ë¦¬ ê³„íš': ''\n",
    "    })\n",
    "# ğŸ”¹ 5. ëª…ì„¸ì„œ ì €ì¥\n",
    "desc_df = pd.DataFrame(desc_list)\n",
    "save_path = \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201811_201811.xlsx\"\n",
    "desc_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\\nğŸ“„ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c7c6f4c-364b-41ef-aa23-46bec50eb929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“„ ìœ„ì¹˜: C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201812_201812.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ”¹ 1. ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "file_paths = [\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/train/2.ì‹ ìš©ì •ë³´/201812_train_ì‹ ìš©ì •ë³´.parquet\",\n",
    "    \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/open/test/2.ì‹ ìš©ì •ë³´/201812_test_ì‹ ìš©ì •ë³´.parquet\"\n",
    "]\n",
    "\n",
    "# ğŸ”¹ 2. ë³‘í•©ìš© ë¦¬ìŠ¤íŠ¸\n",
    "df_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_parquet(path)\n",
    "    ê¸°ì¤€ë…„ì›” = os.path.basename(path).split('_')[0]\n",
    "    df['ê¸°ì¤€ë…„ì›”'] = ê¸°ì¤€ë…„ì›”\n",
    "    df_list.append(df)\n",
    "\n",
    "# ğŸ”¹ 3. ë³‘í•©\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ğŸ”¹ 4. ëª…ì„¸ì„œ êµ¬ì„±\n",
    "desc_list = []\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col == 'SEGMENT':\n",
    "        continue  # â— ì œì™¸í•  ì»¬ëŸ¼\n",
    "\n",
    "    col_type = str(merged_df[col].dtype)\n",
    "    nulls = merged_df[col].isnull().sum()\n",
    "    nunique = merged_df[col].nunique()\n",
    "    var_type = 'ì—°ì†í˜•' if col_type in ['int64', 'float64'] else 'ë²”ì£¼í˜•'\n",
    "\n",
    "    # ì´ìƒì¹˜ ê³„ì‚° (ì—°ì†í˜•ë§Œ)\n",
    "    if var_type == 'ì—°ì†í˜•':\n",
    "        Q1 = merged_df[col].quantile(0.25)\n",
    "        Q3 = merged_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = merged_df[\n",
    "            (merged_df[col] < Q1 - 1.5 * IQR) | (merged_df[col] > Q3 + 1.5 * IQR)\n",
    "        ].shape[0]\n",
    "    else:\n",
    "        outliers = 'N/A'\n",
    "\n",
    "    # ì˜ˆì‹œê°’: ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  ê³ ìœ ê°’ ìƒìœ„ 5ê°œ\n",
    "    example_value = list(merged_df[col].dropna().unique()[:5])\n",
    "\n",
    "    desc_list.append({\n",
    "        'ì»¬ëŸ¼ëª…': col,\n",
    "        'ë°ì´í„° íƒ€ì…': col_type,\n",
    "        'ê²°ì¸¡ì¹˜ ìˆ˜': nulls,\n",
    "        'ê³ ìœ ê°’ ìˆ˜': nunique,\n",
    "        'ì´ìƒì¹˜ ìˆ˜': outliers,\n",
    "        'ë³€ìˆ˜ ìœ í˜•': var_type,\n",
    "        'ì˜ˆì‹œê°’': example_value,\n",
    "        'ì²˜ë¦¬ ê³„íš': ''\n",
    "    })\n",
    "# ğŸ”¹ 5. ëª…ì„¸ì„œ ì €ì¥\n",
    "desc_df = pd.DataFrame(desc_list)\n",
    "save_path = \"C:/Users/HR/Desktop/workspace/íŒŒì´ë„í”„ë¡œì íŠ¸/ì‹ ìš©ì •ë³´_ëª…ì„¸ì„œ_201812_201812.xlsx\"\n",
    "desc_df.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… ëª…ì„¸ì„œ ì €ì¥ ì™„ë£Œ!\\nğŸ“„ ìœ„ì¹˜: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de6c64-64db-4c8f-a3bb-31b5dba5af05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
